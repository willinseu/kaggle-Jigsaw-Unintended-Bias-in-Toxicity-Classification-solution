{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd;pd.set_option('display.max_column',300)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "import re\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dropout,Dense,Embedding,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_FEATURE = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>black</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>christian</th>\n",
       "      <th>female</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>hindu</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>jewish</th>\n",
       "      <th>latino</th>\n",
       "      <th>male</th>\n",
       "      <th>muslim</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:41.987077+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:42.870083+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:45.222647+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:47.601894+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-09-29 10:50:48.488476+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                                       comment_text  \\\n",
       "0  59848  0.000000  This is so cool. It's like, 'would you want yo...   \n",
       "1  59849  0.000000  Thank you!! This would make my life a lot less...   \n",
       "2  59852  0.000000  This is such an urgent design problem; kudos t...   \n",
       "3  59855  0.000000  Is this something I'll be able to install on m...   \n",
       "4  59856  0.893617               haha you guys are a bunch of losers.   \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   bisexual  black  buddhist  christian  female  heterosexual  hindu  \\\n",
       "0       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "1       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "2       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "3       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "4       0.0    0.0       0.0        0.0     0.0           0.0    0.0   \n",
       "\n",
       "   homosexual_gay_or_lesbian  intellectual_or_learning_disability  jewish  \\\n",
       "0                        NaN                                  NaN     NaN   \n",
       "1                        NaN                                  NaN     NaN   \n",
       "2                        NaN                                  NaN     NaN   \n",
       "3                        NaN                                  NaN     NaN   \n",
       "4                        0.0                                 0.25     0.0   \n",
       "\n",
       "   latino  male  muslim  other_disability  other_gender  \\\n",
       "0     NaN   NaN     NaN               NaN           NaN   \n",
       "1     NaN   NaN     NaN               NaN           NaN   \n",
       "2     NaN   NaN     NaN               NaN           NaN   \n",
       "3     NaN   NaN     NaN               NaN           NaN   \n",
       "4     0.0   0.0     0.0               0.0           0.0   \n",
       "\n",
       "   other_race_or_ethnicity  other_religion  other_sexual_orientation  \\\n",
       "0                      NaN             NaN                       NaN   \n",
       "1                      NaN             NaN                       NaN   \n",
       "2                      NaN             NaN                       NaN   \n",
       "3                      NaN             NaN                       NaN   \n",
       "4                      0.0             0.0                       0.0   \n",
       "\n",
       "   physical_disability  psychiatric_or_mental_illness  transgender  white  \\\n",
       "0                  NaN                            NaN          NaN    NaN   \n",
       "1                  NaN                            NaN          NaN    NaN   \n",
       "2                  NaN                            NaN          NaN    NaN   \n",
       "3                  NaN                            NaN          NaN    NaN   \n",
       "4                  0.0                            0.0          0.0    0.0   \n",
       "\n",
       "                    created_date  publication_id  parent_id  article_id  \\\n",
       "0  2015-09-29 10:50:41.987077+00               2        NaN        2006   \n",
       "1  2015-09-29 10:50:42.870083+00               2        NaN        2006   \n",
       "2  2015-09-29 10:50:45.222647+00               2        NaN        2006   \n",
       "3  2015-09-29 10:50:47.601894+00               2        NaN        2006   \n",
       "4  2015-09-29 10:50:48.488476+00               2        NaN        2006   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
       "0  rejected      0    0    0      0         0              0.0   \n",
       "1  rejected      0    0    0      0         0              0.0   \n",
       "2  rejected      0    0    0      0         0              0.0   \n",
       "3  rejected      0    0    0      0         0              0.0   \n",
       "4  rejected      0    0    0      1         0              0.0   \n",
       "\n",
       "   identity_annotator_count  toxicity_annotator_count  \n",
       "0                         0                         4  \n",
       "1                         0                         4  \n",
       "2                         0                         4  \n",
       "3                         0                         4  \n",
       "4                         4                        47  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train['target']>=0.5,'target'] = 1\n",
    "train.loc[train['target']<0.5,'target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                     0.000000\n",
       "target                                 0.000000\n",
       "comment_text                           0.000000\n",
       "severe_toxicity                        0.000000\n",
       "obscene                                0.000000\n",
       "identity_attack                        0.000000\n",
       "insult                                 0.000000\n",
       "threat                                 0.000000\n",
       "asian                                  0.775536\n",
       "atheist                                0.775536\n",
       "bisexual                               0.775536\n",
       "black                                  0.775536\n",
       "buddhist                               0.775536\n",
       "christian                              0.775536\n",
       "female                                 0.775536\n",
       "heterosexual                           0.775536\n",
       "hindu                                  0.775536\n",
       "homosexual_gay_or_lesbian              0.775536\n",
       "intellectual_or_learning_disability    0.775536\n",
       "jewish                                 0.775536\n",
       "latino                                 0.775536\n",
       "male                                   0.775536\n",
       "muslim                                 0.775536\n",
       "other_disability                       0.775536\n",
       "other_gender                           0.775536\n",
       "other_race_or_ethnicity                0.775536\n",
       "other_religion                         0.775536\n",
       "other_sexual_orientation               0.775536\n",
       "physical_disability                    0.775536\n",
       "psychiatric_or_mental_illness          0.775536\n",
       "transgender                            0.775536\n",
       "white                                  0.775536\n",
       "created_date                           0.000000\n",
       "publication_id                         0.000000\n",
       "parent_id                              0.431413\n",
       "article_id                             0.000000\n",
       "rating                                 0.000000\n",
       "funny                                  0.000000\n",
       "wow                                    0.000000\n",
       "sad                                    0.000000\n",
       "likes                                  0.000000\n",
       "disagree                               0.000000\n",
       "sexual_explicit                        0.000000\n",
       "identity_annotator_count               0.000000\n",
       "toxicity_annotator_count               0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1902194/1902194 [00:26<00:00, 71196.75it/s]\n"
     ]
    }
   ],
   "source": [
    "list_all = list(train['comment_text'])+list(test['comment_text'])\n",
    "from tqdm import tqdm\n",
    "length_list = []\n",
    "word_all = []\n",
    "for i in tqdm(list_all):\n",
    "    length_list.append(len(i))\n",
    "    for j in i.split():\n",
    "        word_all.append(j)\n",
    "set_all = set(word_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a sentence has max words: 1971\n",
      "a sentence has min words: 1\n",
      "a sentence has average words: 297\n",
      "there are total 1731089 unique words\n"
     ]
    }
   ],
   "source": [
    "print(\"a sentence has max words:\",max(length_list))\n",
    "print(\"a sentence has min words:\",min(length_list))\n",
    "print('a sentence has average words:',int(sum(length_list)/len(length_list)))\n",
    "print('there are total',len(set_all),'unique words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = []\n",
    "temp = ''\n",
    "for k in set_all:\n",
    "    common = 'qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM'\n",
    "    for l in common:\n",
    "        k = k.replace(l,'')\n",
    "    list_1.append(k)\n",
    "# set(list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_1 = ''\n",
    "for i in list_1:\n",
    "    str_1+=i\n",
    "set_1 = set(str_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¬ø\\uf070Îì§üåëÏö©üåÑ‚ö†Îìú√ñÂæóŒ¨·πë‚Ñ¥ùüÆ‰ª∂0üçóÔøº‚óï‚ö≤ùü∞‰ΩÜÁõ¥üòäœáÈöú·¥∑üëã–π—ï‡´ÄË±°‰π∞·ëØüê±‰ªñ⁄ÜÌíà‚ÇÇ^·ìÇüí§Èîüƒô‚ñäùò∞‡•çÍ≤©ùíö¬ºüåêË∞äü§ï√ú‚á§ÂΩìùë∞‚îäùüñùòÇ‰ΩúüòÆ\"“ªƒïŒ©ÕùÂõΩ‡ººËã±ùë´üë≥ÎèÑùíÇ‚ôÇÊñØùôùœÖÊää É‚Ä¶‚õìË∞∑ÂÖ≥Ôº¢‚îÉüëàüö∂ùñÜùê•ùñç‚òπüòçùêû√†ùë¥ùíÜü§ó·¥ë·∫Ω≈ìü§ìÔº©Œë…ô‚ùó‚òº]‚íä◊ì‡™ú‚úì„Äî…úÊü•Á§æ\\uf0e0üóΩ‚óê—ô‚Äíœâüåèüë≤„Ç∏üåüùëæ‚ñ∞‚ñ∑üì∫üåéùìå‰∏éùò®‚ù£·ΩêüòíÌïò‡™§ùò∏üíÄ≈æùêÖ‚áíÏùÑü•úŒõùóú‚ñ∂\\x80‚ù•‡±¶ü•òÔº°üíä„ÄÅüôÄ6üò¢üòóÊÄ™Êã∑ùë¶Ï•ê„Çµ‚Ñ¢‚òëùó¢–ü¬±ùóª‚ïëùê£üôÉ„ÇàüëºËî°Í∞à‚íå‚û°·¥ã1üë§+üèøüëÆüá∏üê¥Œ∏üë•üê∂‚å†\\u200eÔºµüêæ·êßÔΩúùíÖùó§ü¶ä◊¢ÿ©_◊ßüçΩùôÆ◊ûüá∞ÔΩÇ·øÜÎ∞ò◊†ùìøùôÄÎßà‚õ∑‚ùåÕûÕüüåØ‚ÄêùíÑüòê\\x95„Ñ∏Íú•‚ÄºƒÅ’¥üïâ‡Ø¶üåÖ–íÔºéÎÇò‚ñ†ü¶ÅÔΩï‚Ä†¬Øüåô>‚§µÁßØŒ∑‚úãüë∂üìâ‰∏ãüòôùìÖÁâπÃÖ‚ñëüö¢‚ô´Áªè’§–†üòñ‚Å¥ŸÇ\\x81ƒõ…¢Âùè—Ü–∏‚íâ/Ê≠å◊®‚òéùêòü§òüé∏‚Ñ≥ƒùüéâ·¥¶üíéùüìƒü‰∫∫√±ùìµüéÜ¬ÆÂú∞Êù•–ª‡™æÊãø‚Ä¢‚úòÔºíüèàüçªƒêùêÄÂ∑±ÿµ–ïÌï©‚ñôüêé:“ØÂá∫\\U0001f92fÌã∞üôÅÊàêùòäüëë\\x10‚ÄòÃÑ…õüåπÔ∑ª„Äç·º±Œæ€©„Å§ËÆ©üèπ—ÄÔ¨É‰Ω†‚¨≠\\'ü§¥ùìÆùêÉ‚ö°‰∫ã–Ωüò•·¥è«ßŒü·π£Ÿá√Æ–µùô¢Âéª\\uf0b7<Ôº≠ÈóÆÔºßÎêúùñû‡ºΩœé‚ïöü§∑Ê±âÂçç‚Äñü§û·¥ä‚î£Œøùôòùóû\\x91–öÔΩÖ…î‚õ≤ÔΩÅÎïåÈ¢ùÂêóùòÅüòâÂú£Ã±‚ñïüëÖüíìÂçé–¢‚ñÖüáÆùò±‚Ü≥Îã§Ïïä‚Äû\\x9cüé∞ùòá‚óæüöÑ·æ∂\\uf029\\x96ùêîƒ∫üî®ùëØÊãâ…™üóØùüéùíì èüê°Œªüé®·ìÉùüî·¥á\\u202dÊàò∆Ñùíé@√∑–≥·Ω∏\\uf09aüíÉùíΩ‚Ä∞·ΩÖùòÜ‚ô°üò™‚ãÜùñöüéª‚â§‚â•√ØÂ≠ê–ûÌô© üùüèüéäùò≤ü§≥ÔºêüéìË¥∫\\ue014\\u200b‚ï™‚ú¨Ÿê—âùëß‚úíüçáùìº‚ñ±üôå—Öüòµüõ≥ËøôÎ§ºÊïÖ·ºëüçïùò™üîõÔΩç‚ÅçŒíÔ¨Ç‚àéÂ±à‚òù‚Ñã≈ùü§¢—ÑùñãÏÑùÁõ∏È¨º‚Üì\\uf028üèíüòß“ì~‚ñàùóØƒØ·µâùíåùìí·ê£üë®√ôùê≠üá¥Êó∂ùôóÎåÄùê∞Ô¨Å8üï∫ùñïüî•ÊûÅ‚Ñíùíä&üò≠Œ¥√òÊôÆüëÜ‚ôçüçü?ùë™ùò•Œº‚Åâ‚öú√≥‚Ä≤ùë¨üòÜÊÄíüçäùóüÂπ¥ÂÖ®üò∫¬´üôâ‚öΩùòÄüò¶ÔΩåÊ≥ïùô¨‚ò†√¨‚èèüëèÔΩí∆Ω·¥ò‚ÖõÈ∏°‚óèÏú†ùôáùê¶ÏÑ±ùíôüíÖ‚óûÌôîüëäùêë√Ωùíï√äƒÉ◊ó)ÂØì‚ÄùÏù∏≈ºùë∑ÏÑ∏\\x92üèΩ’±ùô§ÂçñÔºèüöΩ‚ïåÿ°·Ω°‚ñÜüèù÷ÇÂì•‚Ç¨ÔºüÁªìÿ¢üåçùê®üëÄùíáÏä§üèÄË±Ü‰ª•‚Äîùô†–•·ìáÂ§±üëÇüíó‚ñ≤–ì‚ñì\\x9düòéüí•üê≤—á·¥çüéÉ„É´ÂÖãÃàùêáüò£ùñá√¥ùñú‚ù§Â¶Çùó±ÊÅê…ê‚îàŸâ„Å£‚òôÁæéÏÉÅÂÄô„ÅÜœÇ·Ω∞Ôø¶ÿÆùóïƒßÕ¶üòûüö¨üòÅÊ†™ í ∑Ãõ‚Üôüéæüé•ùë≤üíîÔºö7Êâπ‚è∫‚ñãÏïàüáº\\uf02dÊ†ó‚ùß≈Ωùó∑üåà‰ø°\\x9f¬µÔº∑ùê¨ƒ∞„É¨‚îÅ‚©õ‚ñ∏üîº⁄°ùôè‚ãÖ‚òÜüåû\\uf202üñïùìΩ\\u200c·ê∏ÔΩì\\uf04cùòø–ñ–õüêáÔºâÀô‹Å\\u202aÂúÜüçîùñâùìäÍ≤Ω‰∏≠ùó∂ÔºØ·ë≤Á®éüì£≈õÂÆ†\\x13üêµ‚òÉ·ΩÅüë∫‰∫õÔº¥ùôü‡µ¶üíêÁâà\\uf222ü§íüèê◊üüêä‰∏ÄÎ¶¨ÃØüòõŒ≤üáß◊¶üçÜ√åüáªÎãàËàûùüó‡™óÿßËØù¬Ωüíùüöå‚úÄüí∞üöÄÔºÆÏãú√èùíê√¢—ãÔΩî ñüöÇ‚ï±üò∂Ôºº‚íà◊ëËØ¥¬§‚óã‚úåùóµ‚¶Å ª√®ùìÉ√∞Ê≤πÎäî‚ÄôüòîŒπüëΩ·î≠–¥‚òê—õŒ≠‰ª¨Ìïú–ØÁÇπùê´üê∑{‚úû‡πèùñüÁü•!œÉ’µÊ¥ª’Å‚Öî‚àÜüöì·∏∑üòáüáæŒ∂¬ªùêÇ„ÉûÁúãüö¥ÁöÑËÅä‚õë¬•Èôç≈öùò≠üòåƒèùó™\\uf032Œû‚ï≠‚Ä∫üëøùêõ«éüç≠ùôØ–§üê∞Â§ß√áÿ≠–º\\uf410≈çŒùüèºœñ·óû—Å≈ÇÃÅüê≥√≠‚óáü§¶ùíë◊êüéÑÔΩèüëáüëª·µªÔºûüòÉÊâÄÿ≤ùíí‚óÑ–±√ç·º¥‚ñÑÊàëƒóÔΩÜ◊î‚†Äüò°—å‚èñüå†œÄ·øÉ≈ôÀàÊõæ€ûÂ±Å‡™∞ÊÉ≥◊©√π‚äÇÂæíüôÇùü¨‚àµüá´ÌÉ±Âõ†—èÊúàüò≥·é´Ôºåü§êÊñ∞Í∏àüêªùôãŸÉüèÜƒì‚Äë Äüííùò¶ùëπ‚ñ™Ê†∑‚ÅÑ‚íç‚ÑÆùòßùíòŸÅ ºÂÆ∂·ê¶√´√ºüéÖ√Åùüê·Ω¥Á®£ùê¢ÊÆä‚ôæ≈ãùñôùñëüá¨‰∫Üÿ¥ü§£üïçùòπÍ∞Ä√∏œàÔΩÑÂú®‚ÇÑùñò√üü§†ùô•\\ue602\\uf469Ê≤ª·¥∫ŸÜÏóê·ºå€å„ÅïÍ≤å‚Ñ†\\\\‚â†üêïùôß\\u200fÃ£·ºê‚ñÇùôÖƒá‚ñ¨‚àèÁôæùñê◊™–îùôñÊà¶‚ú®ùê≥5üôä„Çπ\\uf005·Ωñ`ÔΩéüè°ùë≥üíõ‚¨Øùê™ÔΩà·ø¶üçÄ√àÏùò√°ùó¥Ë¶Å«í‚ò∫üòòùìà·∫Éü¶Ñüí´‚Äøüçí·ë≥‚éåùôôùò¥üá≤Ìï¥Â©öÂà§…í|„ÅÆÊñ§Êî∂üí≥√•üôÑüç∏ŒΩ‘ú„Ääùóô–ë⁄©ùó†üìç—Éùíñüê¢¬ßËÄ∂ÿ•·èß‰∏î‚Üêƒ•‚òªüç©ùôöüî´Õ° äÀ¢«î„ÄåüêÑùê≤‚ñ∫üë†ùò§…ëüêë—àüé∂ŸÖÌä∏ŒúËÆ§Ôº™Ëôö‚àíüíïùíÅùëª√ß·¥Öùô°·íß√øÿ®üòÑùôîüòù’°Œ∫‚Ü∫Ëá≥‚ú∞»ôüá≠\\uf818·øñüòÇüåÆ‚úèüïä√Ü ïüòü√Äƒâ·Ω†üëÉ‚ïê\\ue600üíú·ΩÄùüïÁáªùü±Ôº≥ÂΩº‚öæùóºü§ë ôùô£‚ô≠ËÉú‚íãùïø\\ue607\\x7füáµÊñáü§§üòØüíã√≤√Ö9Ëøòùê†ùòµÁù£ùò¨üò∑ùóÆ\\uf03d¬¨Ã≤‚ùÜùò∫–∂\\u202cÏöî‚î≥ÔΩóüá∫üëêùóΩ‚äòùóß4ÔøΩ—ëüò´‚ÖìŸäŒµÁîü\\uf04aüèæüï∑Èí±·¥Ä‚õ∏ùí∏ùô©È¢òùêù–£»ªùòñ·µò‚ö≠·Ωëüê∏‡§ïüôÖ·¥úü•Ç„Ç® å·¥ÑÂà´ùë∂≈øùôçùó∏ùê±ÿ£üôã√§üéé‰º†·æΩùëµÂØπ2„Ç∑Â§öùòêËØ≠üòì*‡§∞Ÿé·ãé·ªáÏûòùñåÿπüéá‚Åéÿ™Ïñ¥\\ufeff‚ïÆ‚ùÑùíâÂÖ¨ùí©≈´‚îó√µ’∂Êìç‚¨áùêØüëâüòïÏÇ¨’º‚à¥üéµ[Î∂ÑüòãÊ≤°üèâŒ≥ü¶Ü‰æãüëπ‰º¶ÏïºùíèÂà∞ÁôΩ\\ue608◊úùíÉ·µóÔºò¬æùò©ùíî„Éã\\uf061’•Áåúüîπ ∏‡ªêÊÉß‚òòÂèØ‚òï–øŒ§Œï√©·Ωªüá¶‚≠êËá™·ºî„ÄÇÎßåÊÑ§\\U0001f92a\\ue807Ã∂üå§üíòÊïô$üé´üíµùò∂Ê≠ª‚ÄöÏßÄüò§üåù·ºÄË∞ì‚ó¶÷Ä\\uf031Âúü‚ñ´ÊùÄ‚õΩüçÅùò£ùíÄùó≥üí≠ÔºÅ‚öÜ‚Çµùô™üçéÏôÄü§ñÂ≠©‚ñÄùêöùñìüêÄüòÄüá®‚óîÈÉΩ¬∞üá±Â§ñÈòøË£ΩùôÉ¬©ùì¨«´üñíüôÜüëæùìÅÏù¥…°‚ÜíÁæ§Îü∞„É≥ùô´Âáª‚ñÉüéπùêäùê©Â§©‚Äïüñ§ùíó‚§èüéºÂ†ÇÔº£üö™Ô∏èüÜïÔº∞∆∞–æüêüüöøùêéùôàùêß‚¨Üùü≠üòë‚òÄùóøùó¶ùñóüëÅ„É™Õúùôä‚ñá‚òúÏ†úÂîØ}·ë≠‚ùî‚ÇÅüí™üíØùó≠ÔºÖüêΩùë∫ŒÆùíªüêÆÊú¨ƒÄùìâ%ü§°‚úÖ‚àï‚ó°‚ÄìÂ•Ω¬≤„ÇØùòÑÁêÜüñê‚âà·¥óüêùÀå…©Áâ©‚ÇÉùëÆüíûùêÆ‚è©-Âíåüëé·ºïÏÑúùó≤◊òüé≤ùóπœç\\uf0a7Ï∫ê‡Æú‚òûüî§‚ñí‚ÑÉüîó3Âèã‚û§Ê¨¢Áå¥ùíà„ÉÅ◊õ#ùòºÂçê‚ô™üí©Ëµ¢üèÉ·º°üç∑ÈâÑùï∏·ºÖ·ä†Â£´ÔΩâüá≥√óùò¢üê¶ùíç‚óùÊé•Õ∫‚ÑØüëå¬∏ÂÅΩÌå®ùí∂‰ºöÂõ≠ ∞Ôº≤·ø≥üé≠üîî‚úî√éÍ¥ÄÈÄöüéà„Çâ\\uf02füñë≈ò‚ôÄÂ§ç=ùìª‚òîÀÜ„ÉÑùüëÁçÑ¬®È™óùòΩ√ëüíñùñíü§öùï¥‚ûïüÜòùíæùêüùñé·é•¬¢¬∫ƒç√ì‚≤è‚≤£–®◊ïÊòéùòÉüí¢ùñÑ√∂Ã®„Öìƒ£ÿ±üë©üò±¬°üèª≈°üçëùòÆ¬π–∑‚Ä≥ü§ô‡§æùìáüîÑ·¥†üôàùôÑùñî¬∑üöë…π‚Ü¥Ôºàüêà ≥Ìóàüöó√∫ÿ∑ËÆ®‚Ä£‚òÅüç¶’´üö≤ƒ≠üçæÎ†µ·µíŒ±≈èùêú‚òõ‰∏∫ùñõ\\uf10aüá©‚è∞‚î´Âºè‚òÆ∆°Â∑®‚Ü©üå∫ùê°·∏•Ÿà\\uf020·ºàÊúâ„ÄãùôíÀ§\\x08üòúœÅ‚ô≤üêÇùò∑\\uf099ùüØùòØ‚ñî„Éªùêì„É≠‚Äú‚û•·Ωº‚ÑÖùë≠ÔΩáüë£√£‚àöÂá∏ƒ± øÀöÁ≥ªÂÜ¨◊ùÂ∞è·∏µ–òÃ¥ ú‚ô•ùì≤√îÔºç¬£‚òÖùóò—ç.üéÅ‰ºé·ø∑ùó∞‚öìüèÇ◊ö–°‚úßüòÖùìéùô®üç∫‚Ñê(ùôÜœåÏïΩ‚ïØü¶çüëÑÂÖª‚ô©ùïæüí≤ÿ∫◊§‚áåùñäùôú‚àºÊîøüíüÿüü§ß·ºÑ‚à©üí®üç∞≈å‚úæ—é·Ω≤Á•ùùñÇŒ¶ƒ´–∞üôè·¥°üåãÊ∏©ŸÑüêã Å◊ôÊ£Äùì¥·¥®‚ñèÂÖ∂üôá‚úäÏòÅ‚òÑœÑ\\xadÿ≥·¥µùìÄÿØ·ø∂üëç·ê®üò¥ùò´Íµ≠√¶\\ue613ùêç·ÉöüèÑùë•üòà·ëé–≤’Ω\\u200dÁî®ÀêÔΩãüò∞üóë≈Ñüò¨‚ú≠„Éè–ù‡§ÆÔºáüò†œÜ‚≠ï‚ï≤«ê\\uf071ùòì‚ô¨¬¥·º∞‚òè’∞üíôŒØŒîüá™„Å™Ï¥à‚õ∫ùòæüíöÿ¨·¥õüéØ·º∏üêíüò≤ùü≤üòº√â≈πùò≥üö´üìöùô≠Î°ù\\uf203Âä†üå∏‚ÇÄùíõüòè–Ü·¥º‚Üëüí∏üò®–ú‚ï∞Áªôƒ°·Ω∫ùôõ‚òí;ùó∫üî≠‚àô‚ùìÔΩôùêôÔº•ƒ∏ÊòØ‚àûËØÜ,ùòÖ ≤ùíãùùàÂü∫üá∑‚Äõ≈•—ó«Ä…¥·êÉ‚ÇΩ·Ω∂Ô¥ø‚¨Ö¬≥–óüò©ÔΩÉü§•ùë±√™—ñ¬∂ùü≥Ôº®ùüí‰∏çü§îùôûùñà‡´Å–ê◊£√Ñ◊°·ìÄÔΩñüêç·ºπ‚úàüí°—Ç‚Ñè√ªËøéÔ¥æùë©–∫‚ò≠ËÆÆüáπ'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_1 = ''\n",
    "for i in set_1:\n",
    "    punct_1+=i\n",
    "punct_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_dict = {\"aren't\": \"are not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\"dom't\":\"do not\",\n",
    "                 \"didn't\": \"did not\", \"does'nt\": \"does not\",\"doesn't\": \"does not\", \"don't\": \"do not\",\n",
    "                 \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                 \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\",\"here's\":\"here is\",\n",
    "                 \"i'd\": \"I had\", \"i'll\": \"I will\", \"i'm\": \"I am\", \"isn't\": \"is not\",\n",
    "                 \"it's\": \"it is\", \"it'll\": \"it will\", \"i've\": \"I have\", \"let's\": \"let us\",\n",
    "                 \"mightn't\": \"might not\", \"mustn't\": \"must not\", \"shan't\": \"shall not\",\n",
    "                 \"she'd\": \"she would\", \"she'll\": \"she will\", \"she's\": \"she is\",\n",
    "                 \"shouldn't\": \"should not\", \"that's\": \"that is\", \"that''s\":\"that is\",\"there's\": \"there is\",\n",
    "                 \"they'd\": \"they would\", \"they'll\": \"they will\", \"they're\": \"they are\",\n",
    "                 \"they've\": \"they have\", \"we'd\": \"we would\", \"we're\": \"we are\",\"wasn't\":\"was not\",\n",
    "                 \"weren't\": \"were not\", \"we've\": \"we have\", \"what'll\": \"what will\",\n",
    "                 \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "                 \"where's\": \"where is\", \"who'd\": \"who would\", \"who'll\": \"who will\",\n",
    "                 \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                 \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n",
    "                 \"you'll\": \"you will\", \"you're\": \"you are\", \"you've\": \"you have\",\"opp's\":\"opps\",\n",
    "                 \"'re\": \" are\", \"wasn't\": \"was not\", \"we'll\": \" will\", \"tryin'\": \"trying\",\n",
    "                \"ican't\":\"I can not\",\"are't\":\"are not\",\"dind't\":\"did not\",\"whataboutism\":\"what about ism\",\n",
    "                \"ya'know\":\"you know\",\"havent't\":\"have not\",\"how'd\":\"how had\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_1(data):\n",
    "    '''\n",
    "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
    "    '''\n",
    "    punct = punct_1.replace(\"'\",'')#È¶ñÂÖàÂéªÊéâÈô§‰∫ÜÂçïÂºïÂè∑ÁöÑÂÖ∂‰ªñÂ≠óÁ¨¶„ÄÇÂçïÂºïÂè∑Âú®ÊâßË°åÂÆåËØØÊãºÂêéÂÜçÂéªÈô§„ÄÇ\n",
    "    def clean_special_chars(text, punct):\n",
    "        for p in punct:\n",
    "            text = text.replace(p, ' ')\n",
    "        return text\n",
    "\n",
    "    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_misspell(misspell_dict):\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(misspell_dict.keys()))\n",
    "    return misspell_dict, misspell_re\n",
    "\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    misspellings, misspellings_re = _get_misspell(misspell_dict)\n",
    "\n",
    "    def replace(match):\n",
    "        return misspellings[match.group(0)]\n",
    "\n",
    "    return misspellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numbers(x):\n",
    "    return re.sub('\\d+', ' ', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower\n",
    "train['comment_text'] = train['comment_text'].str.lower()\n",
    "test['comment_text'] = test['comment_text'].str.lower()\n",
    "# clean numbers\n",
    "import re\n",
    "train['comment_text'] = train['comment_text'].apply(clean_numbers)\n",
    "test['comment_text'] = test['comment_text'].apply(clean_numbers)\n",
    "# clean the text\n",
    "train['comment_text'] = preprocess_1(train['comment_text'])\n",
    "test['comment_text'] = preprocess_1(test['comment_text'])\n",
    "# clean misspellings\n",
    "train['comment_text'] = train['comment_text'].apply(replace_typical_misspell)\n",
    "test['comment_text'] = test['comment_text'].apply(replace_typical_misspell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_2(data):\n",
    "    '''\n",
    "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
    "    '''\n",
    "    punct = \"'\"#È¶ñÂÖàÂéªÊéâÈô§‰∫ÜÂçïÂºïÂè∑ÁöÑÂÖ∂‰ªñÂ≠óÁ¨¶„ÄÇÂçïÂºïÂè∑Âú®ÊâßË°åÂÆåËØØÊãºÂêéÂÜçÂéªÈô§„ÄÇ\n",
    "    def clean_special_chars(text, punct):\n",
    "        for p in punct:\n",
    "            text = text.replace(p, ' ')\n",
    "        return text\n",
    "\n",
    "    data = data.astype(str).apply(lambda x: clean_special_chars(x, punct))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text again\n",
    "train['comment_text'] = preprocess_2(train['comment_text'])\n",
    "test['comment_text'] = preprocess_2(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>threat</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>bisexual</th>\n",
       "      <th>black</th>\n",
       "      <th>buddhist</th>\n",
       "      <th>christian</th>\n",
       "      <th>female</th>\n",
       "      <th>heterosexual</th>\n",
       "      <th>hindu</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>intellectual_or_learning_disability</th>\n",
       "      <th>jewish</th>\n",
       "      <th>latino</th>\n",
       "      <th>male</th>\n",
       "      <th>muslim</th>\n",
       "      <th>other_disability</th>\n",
       "      <th>other_gender</th>\n",
       "      <th>other_race_or_ethnicity</th>\n",
       "      <th>other_religion</th>\n",
       "      <th>other_sexual_orientation</th>\n",
       "      <th>physical_disability</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>transgender</th>\n",
       "      <th>white</th>\n",
       "      <th>created_date</th>\n",
       "      <th>publication_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>funny</th>\n",
       "      <th>wow</th>\n",
       "      <th>sad</th>\n",
       "      <th>likes</th>\n",
       "      <th>disagree</th>\n",
       "      <th>sexual_explicit</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>this is so cool  it is like   would you want y...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:41.987077+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>thank you   this would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:42.870083+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>this is such an urgent design problem  kudos t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:45.222647+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>is this something I will be able to install on...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-09-29 10:50:47.601894+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>1.0</td>\n",
       "      <td>haha you guys are a bunch of losers</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-09-29 10:50:48.488476+00</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>rejected</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  target                                       comment_text  \\\n",
       "0  59848     0.0  this is so cool  it is like   would you want y...   \n",
       "1  59849     0.0  thank you   this would make my life a lot less...   \n",
       "2  59852     0.0  this is such an urgent design problem  kudos t...   \n",
       "3  59855     0.0  is this something I will be able to install on...   \n",
       "4  59856     1.0               haha you guys are a bunch of losers    \n",
       "\n",
       "   severe_toxicity  obscene  identity_attack   insult  threat  asian  atheist  \\\n",
       "0         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "1         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "2         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "3         0.000000      0.0         0.000000  0.00000     0.0    NaN      NaN   \n",
       "4         0.021277      0.0         0.021277  0.87234     0.0    0.0      0.0   \n",
       "\n",
       "   bisexual  black  buddhist  christian  female  heterosexual  hindu  \\\n",
       "0       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "1       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "2       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "3       NaN    NaN       NaN        NaN     NaN           NaN    NaN   \n",
       "4       0.0    0.0       0.0        0.0     0.0           0.0    0.0   \n",
       "\n",
       "   homosexual_gay_or_lesbian  intellectual_or_learning_disability  jewish  \\\n",
       "0                        NaN                                  NaN     NaN   \n",
       "1                        NaN                                  NaN     NaN   \n",
       "2                        NaN                                  NaN     NaN   \n",
       "3                        NaN                                  NaN     NaN   \n",
       "4                        0.0                                 0.25     0.0   \n",
       "\n",
       "   latino  male  muslim  other_disability  other_gender  \\\n",
       "0     NaN   NaN     NaN               NaN           NaN   \n",
       "1     NaN   NaN     NaN               NaN           NaN   \n",
       "2     NaN   NaN     NaN               NaN           NaN   \n",
       "3     NaN   NaN     NaN               NaN           NaN   \n",
       "4     0.0   0.0     0.0               0.0           0.0   \n",
       "\n",
       "   other_race_or_ethnicity  other_religion  other_sexual_orientation  \\\n",
       "0                      NaN             NaN                       NaN   \n",
       "1                      NaN             NaN                       NaN   \n",
       "2                      NaN             NaN                       NaN   \n",
       "3                      NaN             NaN                       NaN   \n",
       "4                      0.0             0.0                       0.0   \n",
       "\n",
       "   physical_disability  psychiatric_or_mental_illness  transgender  white  \\\n",
       "0                  NaN                            NaN          NaN    NaN   \n",
       "1                  NaN                            NaN          NaN    NaN   \n",
       "2                  NaN                            NaN          NaN    NaN   \n",
       "3                  NaN                            NaN          NaN    NaN   \n",
       "4                  0.0                            0.0          0.0    0.0   \n",
       "\n",
       "                    created_date  publication_id  parent_id  article_id  \\\n",
       "0  2015-09-29 10:50:41.987077+00               2        NaN        2006   \n",
       "1  2015-09-29 10:50:42.870083+00               2        NaN        2006   \n",
       "2  2015-09-29 10:50:45.222647+00               2        NaN        2006   \n",
       "3  2015-09-29 10:50:47.601894+00               2        NaN        2006   \n",
       "4  2015-09-29 10:50:48.488476+00               2        NaN        2006   \n",
       "\n",
       "     rating  funny  wow  sad  likes  disagree  sexual_explicit  \\\n",
       "0  rejected      0    0    0      0         0              0.0   \n",
       "1  rejected      0    0    0      0         0              0.0   \n",
       "2  rejected      0    0    0      0         0              0.0   \n",
       "3  rejected      0    0    0      0         0              0.0   \n",
       "4  rejected      0    0    0      1         0              0.0   \n",
       "\n",
       "   identity_annotator_count  toxicity_annotator_count  \n",
       "0                         0                         4  \n",
       "1                         0                         4  \n",
       "2                         0                         4  \n",
       "3                         0                         4  \n",
       "4                         4                        47  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['comment_text']\n",
    "X_test = test['comment_text']\n",
    "y_train = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(X_train)+list(X_test))\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,    19,     6,    37,  2179,    10,     6,    51,\n",
       "           35,    12,   106,    39,  1032,     2,   186,    19,   124,\n",
       "          162,   349,    97,   216],\n",
       "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,   389,    12,\n",
       "           19,    35,    95,    61,   164,     5,   219,   218,  6411,\n",
       "        17044,   181,    10,    56,     3,    22,     9,   145,   192,\n",
       "           62,     7,    39,    98]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sequence.pad_sequences(X_train,maxlen=220)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen=220)\n",
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 300)         30000000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 30,219,777\n",
      "Trainable params: 30,219,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=MAX_FEATURE,output_dim=300))\n",
    "model.add(LSTM(units=128,dropout=0.2))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "1804874/1804874 [==============================] - 11400s 6ms/step - loss: 0.1937 - acc: 0.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f01f01e8dd8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.read_csv('../input/sample_submission.csv')\n",
    "df_submit.prediction = predictions\n",
    "df_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
